{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# CONFIGURAZIONE E IMPORT\n",
        "# ==========================================\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# =============================================================================\n",
        "# 1. ENVIRONMENT SANITIZATION (Reset)\n",
        "# =============================================================================\n",
        "# We force a return to the container root and wipe the existing repository.\n",
        "# This prevents \"State Leakage\" where old config files or artifacts from a\n",
        "# previous run might corrupt the current execution.\n",
        "print(\">>> Executing Environment Reset (Clean Slate)...\")\n",
        "try:\n",
        "    os.chdir('/content/')\n",
        "    # Force remove (-rf) to handle non-empty directories and git history without prompts\n",
        "    !rm -rf Hawk-AI-CV-Project\n",
        "except Exception as e:\n",
        "    # Pass silently if directory doesn't exist (first run)\n",
        "    pass\n",
        "\n",
        "# =============================================================================\n",
        "# 2. SOURCE CODE RETRIEVAL (Clone)\n",
        "# =============================================================================\n",
        "# Pulling the latest version of the codebase (HEAD) from the remote origin.\n",
        "!git clone https://github.com/leonardoCosta02/Hawk-AI-CV-Project.git\n",
        "\n",
        "# =============================================================================\n",
        "# 3. RUNTIME CONTEXT & PATH CONFIGURATION\n",
        "# =============================================================================\n",
        "repo_name = \"Hawk-AI-CV-Project\"\n",
        "\n",
        "# Change the working directory of the shell/notebook kernel to the project root.\n",
        "%cd $repo_name\n",
        "\n",
        "# CRITICAL: UPDATING PYTHONPATH\n",
        "# By default, Python looks for modules in site-packages and the script directory.\n",
        "# We explicitly inject the current working directory (os.getcwd()) to the TOP (index 0)\n",
        "# of sys.path.\n",
        "# WHY? This allows us to use absolute imports like `from src import config`\n",
        "# regardless of which sub-folder we are currently executing code in.\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "# =============================================================================\n",
        "# 4. DEPENDENCY RESOLUTION\n",
        "# =============================================================================\n",
        "print(\">>> Installing Runtime Dependencies...\")\n",
        "# - numpy: Vector math\n",
        "# - opencv-python: Computer Vision algorithms (Canny, Hough, Homography)\n",
        "# - matplotlib: Visualization and plotting\n",
        "!pip install numpy opencv-python matplotlib\n",
        "\n",
        "# =============================================================================\n",
        "# 5. VERIFICATION\n",
        "# =============================================================================\n",
        "print(\"\\n>>> Setup Complete. Active Runtime Root:\")\n",
        "print(os.getcwd())\n",
        "# Check if imports work immediately to fail fast if something went wrong\n",
        "try:\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "    print(f\">>> Dependencies verified: OpenCV {cv2.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"!!! CRITICAL ERROR: Dependency installation failed - {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FlGubHjEuJjz",
        "outputId": "48c01346-835c-49a4-e6af-4f7822961611"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Executing Environment Reset (Clean Slate)...\n",
            "Cloning into 'Hawk-AI-CV-Project'...\n",
            "remote: Enumerating objects: 803, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 803 (delta 9), reused 0 (delta 0), pack-reused 775 (from 2)\u001b[K\n",
            "Receiving objects: 100% (803/803), 59.54 MiB | 31.06 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n",
            "/content/Hawk-AI-CV-Project\n",
            ">>> Installing Runtime Dependencies...\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\n",
            ">>> Setup Complete. Active Runtime Root:\n",
            "/content/Hawk-AI-CV-Project\n",
            ">>> Dependencies verified: OpenCV 4.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKMTA-mHsBKL",
        "outputId": "e89c2036-e582-4999-ce05-ae1b41b95c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librerie importate. Pronto per il giudizio.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# CELLA 1: CONFIGURAZIONE E IMPORT\n",
        "# ==========================================\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Librerie importate. Pronto per il giudizio.\")\n",
        "\n",
        "COURT_DIMENSIONS = {\n",
        "    'X_MIN': 0.0,\n",
        "    'X_MAX': 8.23, # Larghezza singolo\n",
        "    'Y_MIN': 0.0,\n",
        "    'Y_MAX': 5.485 # Limite della linea di servizio rispetto al fondo\n",
        "}\n",
        "\n",
        "def is_point_in(x, y):\n",
        "    \"\"\"Restituisce True se il punto (metri) Ã¨ dentro le righe.\"\"\"\n",
        "    in_x = COURT_DIMENSIONS['X_MIN'] <= x <= COURT_DIMENSIONS['X_MAX']\n",
        "    in_y = COURT_DIMENSIONS['Y_MIN'] <= y <= COURT_DIMENSIONS['Y_MAX']\n",
        "    return in_x and in_y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MODULE: HAWK-EYE JUDICIAL ENGINE (M3)\n",
        "# Implementation of Step 3 (Parallax Correction) and Step 4 (Kinematic Analysis)\n",
        "# =============================================================================\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "# Metric constraints synchronized with ITF standards and Module 3 calibration.\n",
        "# Note: Y_MAX is 5.485m, representing the Baseline-to-Service Line distance\n",
        "if 'COURT_DIMENSIONS' not in globals():\n",
        "    COURT_DIMENSIONS = {\n",
        "        'X_MIN': 0.0,   'X_MAX': 8.23,\n",
        "        'Y_MIN': 0.0,   'Y_MAX': 5.485  # Real metric depth of the service box\n",
        "    }\n",
        "\n",
        "def is_point_in(x, y):\n",
        "    \"\"\"\n",
        "    Evaluates if a projected world coordinate falls within the court boundaries.\n",
        "    \"\"\"\n",
        "    return (COURT_DIMENSIONS['X_MIN'] <= x <= COURT_DIMENSIONS['X_MAX'] and\n",
        "            COURT_DIMENSIONS['Y_MIN'] <= y <= COURT_DIMENSIONS['Y_MAX'])\n",
        "\n",
        "class HawkEyeJudge:\n",
        "    \"\"\"\n",
        "    Automated line-judging engine that maps pixel trajectories to metric space.\n",
        "    \"\"\"\n",
        "    def __init__(self, homography_matrix):\n",
        "        # Initializing with the 3x3 Homography Matrix from Module 3\n",
        "        self.H = homography_matrix\n",
        "\n",
        "    def pixel_to_world(self, u, v):\n",
        "        \"\"\"\n",
        "        Transforms 2D Image Pixels (u,v) to 3D World Meters (X,Y) via Matrix H.\n",
        "        \"\"\"\n",
        "        point_vec = np.array([u, v, 1.0])\n",
        "        mapped_vec = np.dot(self.H, point_vec)\n",
        "\n",
        "        # Normalize by the homogeneous scale factor (w)\n",
        "        if mapped_vec[2] != 0:\n",
        "            return mapped_vec[0] / mapped_vec[2], mapped_vec[1] / mapped_vec[2]\n",
        "        return None, None\n",
        "\n",
        "    def detect_bounces(self, trajectory):\n",
        "        \"\"\"\n",
        "        STEP 4: KINEMATIC BOUNCE DETECTION\n",
        "        Identifies impacts by analyzing vertical velocity (Vy) sign inversion.\n",
        "        A physical bounce occurs when downward momentum is reversed.\n",
        "        \"\"\"\n",
        "        bounces = []\n",
        "        if len(trajectory) < 10: return bounces\n",
        "\n",
        "        last_bounce_frame = -20 # Prevents duplicate triggers within a 20-frame window\n",
        "\n",
        "        for t in range(2, len(trajectory) - 2):\n",
        "            prev = trajectory[t-1]\n",
        "            curr = trajectory[t]\n",
        "            nxt  = trajectory[t+1]\n",
        "\n",
        "            if prev is None or curr is None or nxt is None:\n",
        "                continue\n",
        "\n",
        "            # Calculate vertical delta (Velocity Proxy)\n",
        "            # In pixel coordinates, Vy > 0 indicates descent (approaching court bottom)\n",
        "            v_vel_in  = curr[1] - prev[1]  # Velocity entering current frame\n",
        "            v_vel_out = nxt[1] - curr[1]   # Velocity exiting current frame\n",
        "\n",
        "            # Logic: Bounce detected if velocity flips from positive (falling) to negative (rising)\n",
        "            is_velocity_reversal = v_vel_in > 0 and v_vel_out <= 0\n",
        "\n",
        "            if is_velocity_reversal:\n",
        "                # Amplitude check: Ensure the change is not just tracking jitter\n",
        "                if v_vel_in > 2:\n",
        "                    if (t - last_bounce_frame) > 15:\n",
        "                        bounces.append({\n",
        "                            'frame': t,\n",
        "                            'pixel': curr\n",
        "                        })\n",
        "                        last_bounce_frame = t\n",
        "        return bounces\n",
        "\n",
        "    def adjudicate_video(self, video_path, trajectory, output_path):\n",
        "        \"\"\"\n",
        "        Processes the video, identifies bounces, and overlays the judicial verdict.\n",
        "        \"\"\"\n",
        "        cap = cv.VideoCapture(video_path)\n",
        "        fps = cap.get(cv.CAP_PROP_FPS)\n",
        "        width, height = int(cap.get(cv.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "        out = cv.VideoWriter(output_path, cv.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "        # Identify impact frames using Step 4 velocity analysis\n",
        "        bounces = self.detect_bounces(trajectory)\n",
        "        print(f\"ðŸŽ¾ Impact events identified: {len(bounces)}\")\n",
        "\n",
        "        decisions = {}\n",
        "        for b in bounces:\n",
        "            f_idx = b['frame']\n",
        "            px, py = b['pixel']\n",
        "\n",
        "            # STEP 3: PARALLAX MITIGATION (Ground Contact Offset)\n",
        "            # YOLO detects the ball's center. We apply a +6px offset to py to target\n",
        "            # the ball's base, ensuring the projection lies on the ground plane.\n",
        "            py_contact = py + 6\n",
        "\n",
        "            wx, wy = self.pixel_to_world(px, py_contact)\n",
        "\n",
        "            if wx is not None:\n",
        "                # Execute final spatial logic\n",
        "                verdict = \"IN\" if is_point_in(wx, wy) else \"OUT\"\n",
        "                decisions[f_idx] = {\n",
        "                    'verdict': verdict,\n",
        "                    'coords': (wx, wy),\n",
        "                    'color': (0, 255, 0) if verdict == \"IN\" else (0, 0, 255)\n",
        "                }\n",
        "                print(f\"   -> Frame {f_idx}: {verdict} (X={wx:.2f}m, Y={wy:.2f}m)\")\n",
        "\n",
        "        # Main Visualization Loop\n",
        "        frame_count = 0\n",
        "        display_timer = 0\n",
        "        current_display = None\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret: break\n",
        "\n",
        "            if frame_count in decisions:\n",
        "                current_display = decisions[frame_count]\n",
        "                display_timer = int(fps * 2)\n",
        "\n",
        "            # Draw ball trajectory\n",
        "            if frame_count < len(trajectory) and trajectory[frame_count] is not None:\n",
        "                cv.circle(frame, (int(trajectory[frame_count][0]), int(trajectory[frame_count][1])), 5, (0, 255, 255), -1)\n",
        "\n",
        "            # Draw Verdict UI Overlay\n",
        "            if display_timer > 0 and current_display:\n",
        "                cv.rectangle(frame, (50, 150), (450, 320), (0,0,0), -1)\n",
        "                cv.putText(frame, current_display['verdict'], (80, 240), cv.FONT_HERSHEY_SIMPLEX, 3, current_display['color'], 8)\n",
        "                cv.putText(frame, f\"X: {current_display['coords'][0]:.2f}m Y: {current_display['coords'][1]:.2f}m\", (80, 300), cv.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "                display_timer -= 1\n",
        "\n",
        "            out.write(frame)\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "        out.release()"
      ],
      "metadata": {
        "id": "ztCFR0yrsK1r"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# CELLA 3: ESECUZIONE DEL GIUDICE (Versione Robusta)\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np # Importante per la matrice\n",
        "import glob\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# 1. LA TUA MATRICE H\n",
        "# DA SOSTITUIRE (!!)\n",
        "# -----------------------------------------------------------\n",
        "H_MATRIX = np.array([\n",
        "    [ 6.60767767e-02,  2.68232422e-02, -3.15310509e+01],\n",
        "    [-4.44622299e-04, -2.13413995e-01,  1.07256989e+02],\n",
        "    [ 1.94201000e-05,  6.47891119e-03,  1.00000000e+00]\n",
        "])\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "print(\"Inizializzazione Giudice...\")\n",
        "try:\n",
        "    judge = HawkEyeJudge(H_MATRIX)\n",
        "except NameError:\n",
        "    print(\"ERRORE: Inizializzare class HawkEyeJudge !\")\n",
        "    judge = None\n",
        "\n",
        "if judge:\n",
        "    # Cerchiamo i file CSV che iniziano con DATI_\n",
        "    csv_files = glob.glob(\"DATI_*.csv\")\n",
        "\n",
        "    if not csv_files:\n",
        "        print(\"Nessun file 'DATI_*.csv' contenente le coordinate trovato nella cartella corrente.\")\n",
        "    else:\n",
        "        print(f\"Trovati {len(csv_files)} file dati da analizzare.\")\n",
        "\n",
        "        for csv_path in csv_files:\n",
        "            print(f\"\\n\" + \"=\"*40)\n",
        "            print(f\"ðŸ”Ž Analisi file dati: {csv_path}\")\n",
        "\n",
        "            # A. Ricostruisci il nome del video originale\n",
        "            # 1. Prendi solo il nome file (es. DATI_video1.csv) ignorando cartelle\n",
        "            nome_file_pulito = os.path.basename(csv_path)\n",
        "\n",
        "            # 2. Rimuovi il prefisso \"DATI_\" e il suffisso \".csv\"\n",
        "            nome_base = nome_file_pulito.replace(\"DATI_\", \"\").replace(\".csv\", \"\")\n",
        "\n",
        "            print(f\"Cerco il video corrispondente a: '{nome_base}'\")\n",
        "\n",
        "            # 3. Cerca il video in varie posizioni possibili (da modificare !!)\n",
        "            possibili_path = [\n",
        "                os.path.join(os.getcwd(), 'data', 'videos'), # Cartella strutturata\n",
        "                os.getcwd(),                                 # Cartella corrente (/content)\n",
        "                '/content'                                   # Root esplicita\n",
        "            ]\n",
        "\n",
        "            video_path = None\n",
        "            estensioni = ['.mp4', '.mov', '.avi']\n",
        "\n",
        "            for cartella in possibili_path:\n",
        "                for ext in estensioni:\n",
        "                    test_path = os.path.join(cartella, nome_base + ext)\n",
        "                    if os.path.exists(test_path):\n",
        "                        video_path = test_path\n",
        "                        break\n",
        "                if video_path: break\n",
        "\n",
        "            if not video_path:\n",
        "                print(f\"VIDEO NON TROVATO!\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Video trovato: {video_path}\")\n",
        "\n",
        "            try:\n",
        "                df = pd.read_csv(csv_path)\n",
        "\n",
        "                # Trova il frame massimo\n",
        "                max_frame = int(df['frame'].max())\n",
        "\n",
        "                # Crea lista (aggiungo +50 di buffer per sicurezza)\n",
        "                trajectory_list = [None] * (max_frame + 50)\n",
        "\n",
        "                # Riempi la lista\n",
        "                punti_validi = 0\n",
        "                for _, row in df.iterrows():\n",
        "                    try:\n",
        "                        idx = int(row['frame'])\n",
        "                        u, v = float(row['u']), float(row['v'])\n",
        "\n",
        "                        # Controllo base per evitare valori assurdi\n",
        "                        if not np.isnan(u) and not np.isnan(v):\n",
        "                            trajectory_list[idx] = (u, v)\n",
        "                            punti_validi += 1\n",
        "                    except ValueError:\n",
        "                        continue # Salta righe corrotte\n",
        "\n",
        "                print(f\"Caricati {punti_validi} punti di tracciamento.\")\n",
        "\n",
        "                # C. Esegui il giudizio\n",
        "                output_filename = f\"JUDGED_{nome_base}.mp4\"\n",
        "\n",
        "                judge.adjudicate_video(video_path, trajectory_list, output_filename)\n",
        "\n",
        "                # D. Scarica\n",
        "                if os.path.exists(output_filename):\n",
        "                    print(f\"   ðŸ’¾ Download in corso: {output_filename}\")\n",
        "                    files.download(output_filename)\n",
        "                else:\n",
        "                    print(\"Errore: Il video output non Ã¨ stato creato.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Errore durante l'elaborazione di {nome_base}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6vDcTxysPB3",
        "outputId": "bb387787-9156-41e9-8a0e-779945cee32a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizializzazione Giudice...\n",
            "Nessun file 'DATI_*.csv' contenente le coordinate trovato nella cartella corrente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# CELLA DI DEBUG: VISUALIZZA LA GRIGLIA\n",
        "# ==========================================\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "H_MATRIX = np.array([\n",
        "    [6.50980565e-02, 2.65116930e-02, -3.04981716e+01],\n",
        "    [3.86372362e-04, -1.97434738e-01, 7.91002378e+01],\n",
        "    [1.76143090e-04, 6.49680276e-03, 1.00000000e+00]\n",
        "])\n",
        "\n",
        "# 2. Definiamo i 4 angoli del campo (in METRI) secondo il sistema M3\n",
        "# Ordine: [0,0] (Servizio SX), [8.23, 0] (Servizio DX), [8.23, 6.40] (Rete DX), [0, 6.40] (Rete SX)\n",
        "# Usiamo i punti chiave delle righe del singolare\n",
        "punti_metri = np.array([\n",
        "    [0.0,  0.0],   # Intersezione T servizio / laterale sinistra\n",
        "    [8.23, 0.0],   # Intersezione T servizio / laterale destra\n",
        "    [8.23, 6.40],  # Rete / laterale destra\n",
        "    [0.0,  6.40],  # Rete / laterale sinistra\n",
        "    [0.0, -5.49],  # Fondo / laterale sinistra\n",
        "    [8.23, -5.49]  # Fondo / laterale destra\n",
        "], dtype='float32')\n",
        "\n",
        "def disegna_campo_su_frame(frame, H):\n",
        "    # Calcoliamo l'inversa per proiettare Metri -> Pixel\n",
        "    try:\n",
        "        H_inv = np.linalg.inv(H)\n",
        "    except:\n",
        "        print(\"La matrice non Ã¨ invertibile!\")\n",
        "        return frame\n",
        "\n",
        "    # Convertiamo i punti metri in coordinate omogenee [x, y, 1]\n",
        "    h, w = frame.shape[:2]\n",
        "    pts_pixel = []\n",
        "\n",
        "    for pm in punti_metri:\n",
        "        vec_m = np.array([pm[0], pm[1], 1])\n",
        "        vec_px = np.dot(H_inv, vec_m)\n",
        "\n",
        "        # Normalizza\n",
        "        if vec_px[2] != 0:\n",
        "            u = int(vec_px[0] / vec_px[2])\n",
        "            v = int(vec_px[1] / vec_px[2])\n",
        "            pts_pixel.append((u, v))\n",
        "\n",
        "            # Disegna punto\n",
        "            cv.circle(frame, (u, v), 10, (0, 0, 255), -1)\n",
        "            cv.putText(frame, f\"{pm[0]},{pm[1]}\", (u+10, v), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "# --- TEST SU UN FRAME A CASO DEL TUO VIDEO ---\n",
        "video_path = \"JUDGED_video1.mp4\" # <--- CONTROLLA NOME FILE\n",
        "cap = cv.VideoCapture(video_path)\n",
        "ret, frame = cap.read()\n",
        "if ret:\n",
        "    frame_debug = disegna_campo_su_frame(frame, H_MATRIX)\n",
        "    cv2_imshow(frame_debug)\n",
        "else:\n",
        "    print(\"Impossibile leggere il video per il debug.\")\n",
        "cap.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgrV3bF13zAb",
        "outputId": "9f15eb69-6fc8-435a-e3f8-c0a2f1a6de1e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Impossibile leggere il video per il debug.\n"
          ]
        }
      ]
    }
  ]
}